{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/project/grouped_bymean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    \"\"\"\n",
    "    Calculate entropy given a pandas series, list, or numpy array.\n",
    "    \"\"\"\n",
    "    # Compute the counts of each unique value in the column\n",
    "    values,counts = np.unique(column, return_counts=True)\n",
    "\n",
    "    # Compute the entropy\n",
    "    entropy_value = scipy.stats.entropy(counts, base=2)  # the log base 2 of probs computes the bits\n",
    "    \n",
    "    return entropy_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create bins based on the unique values of each column, as entropy cannot be calculated for floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of Employment is: 1.5023831167070347\n",
      "Entropy of Employment_binned is: 1.5023831167070347\n",
      "Entropy of Trolleybus is: 1.3777015874337881\n",
      "Entropy of Trolleybus_binned is: 1.3777015874337881\n",
      "Entropy of number of bikes is: 1.3297524343210707\n",
      "Entropy of number of bikes_binned is: 1.3297524343210707\n",
      "Entropy of Crime Degree is: 1.2922125703636724\n",
      "Entropy of Crime Degree_binned is: 1.2922125703636724\n",
      "Entropy of Ramp // Crosswalk is: 1.23443125288213\n",
      "Entropy of Ramp // Crosswalk_binned is: 1.23443125288213\n",
      "Entropy of RTP is: 1.2073675134491026\n",
      "Entropy of RTP_binned is: 1.2073675134491026\n",
      "Entropy of Crosswalk width is: 1.2049538994125908\n",
      "Entropy of Crosswalk width_binned is: 1.2049538994125908\n",
      "Entropy of Crossing length is: 1.1883993103738217\n",
      "Entropy of Crossing length_binned is: 1.1883993103738217\n",
      "Entropy of e-bike is: 1.17360552746253\n",
      "Entropy of e-bike_binned is: 1.17360552746253\n",
      "Entropy of fully painted crosswalk is: 1.1731955528247415\n",
      "Entropy of fully painted crosswalk_binned is: 1.1731955528247415\n",
      "Entropy of Ramp obstacles is: 1.1661677896620006\n",
      "Entropy of Ramp obstacles_binned is: 1.1661677896620006\n",
      "Entropy of Incline is: 1.134352968212192\n",
      "Entropy of Incline_binned is: 1.134352968212192\n",
      "Entropy of Ramp conditions is: 1.125046075009611\n",
      "Entropy of Ramp conditions_binned is: 1.125046075009611\n",
      "Entropy of Open-Weekdays is: 1.0720794250116639\n",
      "Entropy of Open-Weekdays_binned is: 1.0720794250116639\n",
      "Entropy of Open-Weekends is: 1.037020825943731\n",
      "Entropy of Open-Weekends_binned is: 1.037020825943731\n",
      "Entropy of Width is: 1.0341100872344409\n",
      "Entropy of Width_binned is: 1.0341100872344409\n",
      "Entropy of Business Plugs is: 0.9892268193639908\n",
      "Entropy of Business Plugs_binned is: 0.9892268193639908\n",
      "Entropy of External CCTV is: 0.9892268193639908\n",
      "Entropy of External CCTV_binned is: 0.9892268193639908\n",
      "Entropy of Storefront is: 0.9892268193639908\n",
      "Entropy of Storefront_binned is: 0.9892268193639908\n",
      "Entropy of Storefront_binned_binned is: 0.9892268193639908\n",
      "Entropy of Visible Sign of Business is: 0.9892268193639908\n",
      "Entropy of Visible Sign of Business_binned is: 0.9892268193639908\n",
      "Entropy of Business tables is: 0.9876572435657167\n",
      "Entropy of Business tables_binned is: 0.9876572435657167\n",
      "Entropy of Business WiFi is: 0.9868320906298733\n",
      "Entropy of Business WiFi_binned is: 0.9868320906298733\n",
      "Entropy of Business Internal CCTV is: 0.9841947942474155\n",
      "Entropy of Business Internal CCTV_binned is: 0.9841947942474155\n",
      "Entropy of Access to people with disabilities is: 0.9432719701698704\n",
      "Entropy of Access to people with disabilities_binned is: 0.9432719701698704\n",
      "Entropy of Positive elements is: 0.9312644841108718\n",
      "Entropy of Positive elements_binned is: 0.9312644841108718\n",
      "Entropy of Food joint is: 0.8389996768865503\n",
      "Entropy of Food joint_binned is: 0.8389996768865503\n",
      "Entropy of Physical aspects in poor condition is: 0.7329242112395357\n",
      "Entropy of Physical aspects in poor condition_binned is: 0.7329242112395357\n",
      "Entropy of Coffee Shop is: 0.7070299852119399\n",
      "Entropy of Coffee Shop_binned is: 0.7070299852119399\n",
      "Entropy of Poor infrastructure is: 0.6936572936612688\n",
      "Entropy of Poor infrastructure_binned is: 0.6936572936612688\n",
      "Entropy of Obstacles is: 0.6557908127833307\n",
      "Entropy of Obstacles_binned is: 0.6557908127833307\n",
      "Entropy of Panic button is: 0.6557908127833307\n",
      "Entropy of Panic button_binned is: 0.6557908127833307\n",
      "Entropy of Number of female employees is: 0.6135102413852149\n",
      "Entropy of Number of female employees_binned is: 0.6135102413852149\n",
      "Entropy of Run over is: 0.596092085326912\n",
      "Entropy of Run over_binned is: 0.596092085326912\n",
      "Entropy of Restaurant is: 0.590751550863029\n",
      "Entropy of Restaurant_binned is: 0.590751550863029\n",
      "Entropy of Mean Inhabitants is: 0.5619543792088069\n",
      "Entropy of Mean Inhabitants_binned is: 0.5619543792088069\n",
      "Entropy of Broken drain-cover is: 0.5473098329929192\n",
      "Entropy of Broken drain-cover_binned is: 0.5473098329929192\n",
      "Entropy of risky building is: 0.5169447136688906\n",
      "Entropy of risky building_binned is: 0.5169447136688906\n",
      "Entropy of graffiti is: 0.5166725570264536\n",
      "Entropy of graffiti_binned is: 0.5166725570264536\n",
      "Entropy of Total coverage of transport is: 0.4965795817768849\n",
      "Entropy of Total coverage of transport_binned is: 0.4965795817768849\n",
      "Entropy of school_count is: 0.4536323244364637\n",
      "Entropy of school_count_binned is: 0.4536323244364637\n",
      "Entropy of Lighting Stores is: 0.4491108840797188\n",
      "Entropy of Lighting Stores_binned is: 0.4491108840797188\n",
      "Entropy of mobile vendors is: 0.44710730987287894\n",
      "Entropy of mobile vendors_binned is: 0.44710730987287894\n",
      "Entropy of not painted crosswalk is: 0.44242579587455816\n",
      "Entropy of not painted crosswalk_binned is: 0.44242579587455816\n",
      "Entropy of Incivility is: 0.42906475597187066\n",
      "Entropy of Incivility_binned is: 0.42906475597187066\n",
      "Entropy of Metrobus is: 0.42016580328608955\n",
      "Entropy of Metrobus_binned is: 0.42016580328608955\n",
      "Entropy of tourist map is: 0.3841174837617128\n",
      "Entropy of tourist map_binned is: 0.3841174837617128\n",
      "Entropy of risky pavement is: 0.36839599705498743\n",
      "Entropy of risky pavement_binned is: 0.36839599705498743\n",
      "Entropy of risky road is: 0.35227134950680744\n",
      "Entropy of risky road_binned is: 0.35227134950680744\n",
      "Entropy of homelessness is: 0.335719465696785\n",
      "Entropy of homelessness_binned is: 0.335719465696785\n",
      "Entropy of Accepts credit card is: 0.28320471476585396\n",
      "Entropy of Accepts credit card_binned is: 0.28320471476585396\n",
      "Entropy of excellent street lighting is: 0.28320471476585396\n",
      "Entropy of excellent street lighting_binned is: 0.28320471476585396\n",
      "Entropy of Vertical signs is: 0.2646234479691697\n",
      "Entropy of Vertical signs_binned is: 0.2646234479691697\n",
      "Entropy of partially painted crosswalk is: 0.26112820127081077\n",
      "Entropy of partially painted crosswalk_binned is: 0.26112820127081077\n",
      "Entropy of hospitals_count is: 0.2162640503724643\n",
      "Entropy of hospitals_count_binned is: 0.2162640503724643\n",
      "Entropy of Injuries is: 0.15206071100986848\n",
      "Entropy of Injuries_binned is: 0.15206071100986848\n",
      "Entropy of trash is: 0.13733300103432763\n",
      "Entropy of trash_binned is: 0.13733300103432763\n",
      "Entropy of good street lighting is: 0.1250114856905231\n",
      "Entropy of good street lighting_binned is: 0.1250114856905231\n",
      "Entropy of police presence is: 0.1250114856905231\n",
      "Entropy of police presence_binned is: 0.1250114856905231\n",
      "Entropy of Drug addicts is: 0.11229606757086999\n",
      "Entropy of Drug addicts_binned is: 0.11229606757086999\n",
      "Entropy of Deaths is: 0.110929327422885\n",
      "Entropy of Deaths_binned is: 0.110929327422885\n",
      "Entropy of Vandalism is: 0.07112443253730757\n",
      "Entropy of Vandalism_binned is: 0.07112443253730757\n",
      "Entropy of Broken public property is: 0.061918607505821587\n",
      "Entropy of Broken public property_binned is: 0.061918607505821587\n",
      "Entropy of Public WiFi is: 0.05601949079883343\n",
      "Entropy of Public WiFi_binned is: 0.05601949079883343\n",
      "Entropy of Concessioned is: 0.03985815879347762\n",
      "Entropy of Concessioned_binned is: 0.03985815879347762\n",
      "Entropy of Ice Cream Shop is: 0.03985815879347762\n",
      "Entropy of Ice Cream Shop_binned is: 0.03985815879347762\n",
      "Entropy of Metro is: 0.03985815879347762\n",
      "Entropy of Metro_binned is: 0.03985815879347762\n",
      "Entropy of indication of security is: 0.03985815879347762\n",
      "Entropy of indication of security_binned is: 0.03985815879347762\n",
      "Entropy of Collision is: 0.022073721703463674\n",
      "Entropy of Collision_binned is: 0.022073721703463674\n",
      "Entropy of Federal Judiciary is: 0.022073721703463674\n",
      "Entropy of Federal Judiciary_binned is: 0.022073721703463674\n",
      "Entropy of inclined ramp is: 0.022073721703463674\n",
      "Entropy of inclined ramp_binned is: 0.022073721703463674\n",
      "Entropy of regular street lighting is: 0.022073721703463674\n",
      "Entropy of regular street lighting_binned is: 0.022073721703463674\n",
      "Entropy of vehicle abandoned is: 0.022073721703463674\n",
      "Entropy of vehicle abandoned_binned is: 0.022073721703463674\n",
      "Entropy of Flooding is: 0.0\n",
      "Entropy of Flooding_binned is: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/utils/extmath.py:990: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n",
      "/opt/anaconda/envs/Python3/lib/python3.9/site-packages/sklearn/utils/extmath.py:1020: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
      "/tmp/ipykernel_164/3345340446.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "def calc_entropy(column):\n",
    "    # Compute the counts of each unique value in the column\n",
    "    values,counts = np.unique(column, return_counts=True)\n",
    "    # Compute the entropy\n",
    "    entropy_value = scipy.stats.entropy(counts, base=2)  # the log base 2 of probs computes the bits\n",
    "    return entropy_value\n",
    "\n",
    "# Determine the number of bins for each variable (for instance, 10)\n",
    "n_bins = 3\n",
    "\n",
    "column_to_skip = 'geometry'  # replace with the name of the column you want to skip\n",
    "\n",
    "# Standardize all columns except the one to skip\n",
    "scaler = StandardScaler()\n",
    "df_standardized = df.copy()  # start with a copy of the original dataframe\n",
    "df_standardized[df.columns.difference([column_to_skip])] = scaler.fit_transform(df[df.columns.difference([column_to_skip])])\n",
    "\n",
    "entropy_values = {}\n",
    "\n",
    "for column in df_standardized.columns.difference([column_to_skip]):\n",
    "    # Bin continuous variables\n",
    "    df_standardized[column+'_binned'] = pd.cut(df_standardized[column], bins=n_bins, include_lowest=True, labels=False)\n",
    "\n",
    "    # Calculate entropy and store in the dictionary\n",
    "    entropy_value = calc_entropy(df_standardized[column+'_binned'])\n",
    "    entropy_values[column] = entropy_value\n",
    "\n",
    "# Sort the entropy values in descending order and print\n",
    "for column, entropy_value in sorted(entropy_values.items(), key=lambda item: item[1], reverse=True):\n",
    "    print('Entropy of', column, 'is:', entropy_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[['Employment','Trolleybus','number of bikes','Crime Degree','Ramp // Crosswalk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employment</th>\n",
       "      <th>Trolleybus</th>\n",
       "      <th>number of bikes</th>\n",
       "      <th>Crime Degree</th>\n",
       "      <th>Ramp // Crosswalk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employment  Trolleybus  number of bikes  Crime Degree  Ramp // Crosswalk\n",
       "0         2.0         0.0              0.0           1.5           0.666667\n",
       "1         2.0         0.0             36.0           1.0           0.000000\n",
       "2         2.0         0.0             30.0           1.0           0.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.to_csv('subset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
